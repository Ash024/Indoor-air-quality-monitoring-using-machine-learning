# -*- coding: utf-8 -*-
"""IAQM_Implementation_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FkAPa0MkQxaxDeVK5x8y5b8lT3RI0AXB
"""

#Importing libraries
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

df = pd.read_csv('/content/MP_Data_R.csv')
df

df.info()

sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='viridis')

"""Appplying Preprocessing Technique"""

nullvalues = df.isnull().sum()
nullvalues

df.describe()

df.nunique()

"""Handling missing or null values"""

#Counting the percentage of null values
null_values_percentage = (df.isnull().sum()/df.isnull().count()*100).sort_values(ascending=False)

print("NULL value count:")
missing_data_with_percentage = pd.concat([nullvalues, null_values_percentage], axis=1, keys=['Total', 'Percent'])
missing_data_with_percentage

# Remaining columns with null values
df.isnull().sum()

df

"""Using mean to fill the missing values"""

# null values are replaced with mean for the numerical data
df.fillna(df.mean(), inplace=True)
df.isnull().sum()

sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='viridis')

"""Histogram to understand the distribution of attributes"""

df.hist(figsize = (10,10))
plt.show()

"""Identifying Outliers"""

plt.figure(figsize=(12, 8))
df.boxplot()

"""Analysing Outliers"""

for i in ['PM2.5 (ug/m3)', 'PM10 (ug/m3)', 'NO (ug/m3)', 'NO2 (ug/m3)','NOx (ppb)', 'NH3 (ug/m3)', 'SO2 (ug/m3)', 'CO (mg/m3)', 'Ozone (ug/m3)']:
    def count_outliers_iqr(series):
       Q1 = series.quantile(0.25)
       Q3 = series.quantile(0.75)
       IQR = Q3 - Q1
       lf = Q1 - 1.5 * IQR
       uf = Q3 + 1.5 * IQR
       outliers = series[(series < lf) | (series > uf)]
       return len(outliers)

# Calculate number of outliers for each numeric column
print("Number of outliers in each column:")
outlier_count = df.select_dtypes(include='number').apply(count_outliers_iqr)
outlier_count

print("Total number of outliers in out dataset:")
outlier_count.sum()

"""Handling Outliers"""

#function for detecting outliers
def outlier(col):
  q1,q3=np.percentile(col,[25,75])
  iqr=q3-q1
  lf=q1-1.5*iqr
  uf=q3+1.5*iqr
  return lf,uf

for i in ['PM2.5 (ug/m3)', 'PM10 (ug/m3)', 'NO (ug/m3)', 'NO2 (ug/m3)','NOx (ppb)', 'NH3 (ug/m3)', 'SO2 (ug/m3)', 'CO (mg/m3)', 'Ozone (ug/m3)']:
       lf,uf=outlier(df[i])
       df[i]=np.where(df[i]<lf,lf,df[i])
       df[i]=np.where(df[i]>uf,uf,df[i])

plt.figure(figsize=(12, 8))

df.boxplot()

df.describe()

"""Standard Deviation"""

df.var()

df

"""### The AQI calculation uses 7 measures: PM2.5, PM10, SO2, NOx, NH3, CO and O3.
-->For PM2.5, PM10, SO2, NOx and NH3 the average value in last 24-hrs is used with the condition of having at least 16 values.

-->For CO and O3 the maximum value in last 8-hrs is used.

-->Each measure is converted into a Sub-Index based on pre-defined groups.

-->Sometimes measures are not available due to lack of measuring or lack of required data points.

-->Final AQI is the maximum Sub-Index with the condition that at least one of PM2.5 and PM10 should be available and at least three out of the seven should be available.
"""

#Function to calculate AQI based on PM2.5 value

def get_PM25_subindex(x):
    if x <= 30:
        return x * 50 / 30
    elif x > 30 and x <= 60:
        return 50 + (x - 30) * 50 / 30
    elif x > 60 and x <= 90:
        return 100 + (x - 60) * 100 / 30
    elif x > 90 and x <= 120:
        return 200 + (x - 90) * 100 / 30
    elif x > 120 and x <= 250:
        return 300 + (x - 120) * 100 / 130
    elif x > 250:
        return 400 + (x - 250) * 100 / 130
    else:
        return 0

df["PM2.5_SubIndex"] = df["PM2.5 (ug/m3)"].astype(int).apply(lambda x: get_PM25_subindex(x))
data = df[['PM2.5 (ug/m3)','PM2.5_SubIndex']]
data.head()

#Function to calculate AQI based on PM10 value
def get_PM10_subindex(x):
    if x <= 50:
       return x
    elif x > 50 and x <= 100:
       return x
    elif x > 100 and x <= 250:
       return 100 + (x - 100) * 100 / 150
    elif x > 250 and x <= 350:
       return 200 + (x - 250)
    elif x > 350 and x <= 430:
       return 300 + (x - 350) * 100 / 80
    elif x > 430:
       return 400 + (x - 430) * 100 / 80
    else:
       return 0

df["PM10_SubIndex"] = df["PM10 (ug/m3)"].astype(int).apply(lambda x: get_PM10_subindex(x))
data = df[['PM10 (ug/m3)','PM10_SubIndex']]
data.head()

#Function to calculate AQI based on NO2 value

def get_NOx_subindex(x):
    if x <= 40:
        return x * 50 / 40
    elif x > 40 and x <= 80:
        return 50 + (x - 40) * 50 / 40
    elif x > 80 and x <= 180:
        return 100 + (x - 80) * 100 / 100
    elif x > 180 and x <= 280:
        return 200 + (x - 180) * 100 / 100
    elif x > 280 and x <= 400:
        return 300 + (x - 280) * 100 / 120
    elif x > 400:
        return 400 + (x - 400) * 100 / 120
    else:
        return 0

df["NOx_SubIndex"] = df["NOx (ppb)"].astype(int).apply(lambda x: get_NOx_subindex(x))
data = df[['NOx (ppb)','NOx_SubIndex']]
data.head()

#Function to calculate AQI based on SO2 value

def get_SO2_subindex(x):
    if x <= 40:
        return x * 50 / 40
    elif x > 40 and x <= 80:
        return 50 + (x - 40) * 50 / 40
    elif x > 80 and x <= 380:
        return 100 + (x - 80) * 100 / 300
    elif x > 380 and x <= 800:
        return 200 + (x - 380) * 100 / 420
    elif x > 800 and x <= 1600:
        return 300 + (x - 800) * 100 / 800
    elif x > 1600:
        return 400 + (x - 1600) * 100 / 800
    else:
        return 0

df["SO2_SubIndex"] = df["SO2 (ug/m3)"].astype(int).apply(lambda x: get_SO2_subindex(x))
data = df[['SO2 (ug/m3)','SO2_SubIndex']]
data.head()

# Function to calculate AQI based on NH3 value

def get_NH3_subindex(x):
    if x <= 200:
        return x * 50 / 200
    elif x > 200 and x <= 400:
        return 50 + (x - 200) * 50 / 200
    elif x > 400 and x <= 800:
        return 100 + (x - 400) * 100 / 400
    elif x > 800 and x <= 1200:
        return 200 + (x - 800) * 100 / 400
    elif x > 1200 and x <= 1800:
        return 300 + (x - 1200) * 100 / 600
    elif x > 1800:
        return 400 + (x - 1800) * 100 / 600
    else:
        return 0

df["NH3_SubIndex"] = df["NH3 (ug/m3)"].astype(int).apply(lambda x: get_NH3_subindex(x))
data = df[['NH3 (ug/m3)','NH3_SubIndex']]
data.head()

# Function to calculate AQI based on CO value

def get_CO_subindex(x):
    if x <= 1:
        return x * 50 / 1
    elif x > 1 and x <= 2:
        return 50 + (x - 1) * 50 / 1
    elif x > 2 and x <= 10:
        return 100 + (x - 2) * 100 / 8
    elif x > 10 and x <= 17:
        return 200 + (x - 10) * 100 / 7
    elif x > 17 and x <= 34:
        return 300 + (x - 17) * 100 / 17
    elif x > 34:
        return 400 + (x - 34) * 100 / 17
    else:
        return 0

df["CO_SubIndex"] = df["CO (mg/m3)"].astype(int).apply(lambda x: get_CO_subindex(x))
data = df[['CO (mg/m3)','CO_SubIndex']]
data.head()

# Function to calculate AQI based on Ozone value

def get_O3_subindex(x):
    if x <= 50:
        return x * 50 / 50
    elif x > 50 and x <= 100:
        return 50 + (x - 50) * 50 / 50
    elif x > 100 and x <= 168:
        return 100 + (x - 100) * 100 / 68
    elif x > 168 and x <= 208:
        return 200 + (x - 168) * 100 / 40
    elif x > 208 and x <= 748:
        return 300 + (x - 208) * 100 / 539
    elif x > 748:
        return 400 + (x - 400) * 100 / 539
    else:
        return 0

df["O3_SubIndex"] = df["Ozone (ug/m3)"].astype(int).apply(lambda x: get_O3_subindex(x))
data = df[['Ozone (ug/m3)','O3_SubIndex']]
data.head()

df

# Calculate the final air quality index (finalAQI) of every data value by taking the average
df['AQI'] = round(df[["PM2.5_SubIndex", "PM10_SubIndex", "SO2_SubIndex", "NOx_SubIndex","NH3_SubIndex", "CO_SubIndex", "O3_SubIndex"]].max(axis=1), 2)
df.head()

# Using threshold values to classify a particular values as good, moderate, unhealthy, very unhealthy and Hazardous

def AQI_Range(x):
    if x <= 50:
        return "Good"
    elif x > 50 and x <= 100:
        return "Satisfactory"
    elif x > 100 and x <= 200:
        return "Moderately Polluted"
    elif x > 200 and x <= 300:
        return "Poor"
    elif x > 300 and x <= 400:
        return "Very Poor"
    elif x > 400:
        return "Severe"
    else:
        return '0'

df['AQI_Range'] = df['AQI'] .apply(AQI_Range)
df.head()

# These are the counts of values present in the AQI_Range column.
df['AQI_Range'].value_counts()

"""Feature Selection"""

feature = df[['PM2.5 (ug/m3)',	'PM10 (ug/m3)',	'NO (ug/m3)','NO2 (ug/m3)',	'NOx (ppb)',	'NH3 (ug/m3)',	'SO2 (ug/m3)',	'CO (mg/m3)',	'Ozone (ug/m3)','AQI']]
feature.head()

"""Correlation of selected features"""

plt.figure(figsize=(8,5))
sns.heatmap(feature.corr(), annot=True);

fig, axes = plt.subplots(3, 3, figsize=(15, 15))

# Flatten axes array for easy iteration
axes = axes.flatten()

# Plot each pollutant against AQI
for i, ax in enumerate(axes):
    if i < len(df.columns) - 2:  # Exclude AQI and AQI_Range columns
        sns.scatterplot(data=df, x=df.iloc[:, i], y='AQI', hue='AQI_Range', ax=ax)
        ax.set_xlabel(df.columns[i])
        ax.set_ylabel('AQI')
        ax.set_title(f'{df.columns[i]} vs AQI')

# Adjust layout
plt.tight_layout()
plt.show()

#Models

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn import metrics
from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score
from sklearn.metrics import accuracy_score, confusion_matrix

X= df[['PM2.5 (ug/m3)',	'PM10 (ug/m3)',	'NO (ug/m3)','NO2 (ug/m3)',	'NOx (ppb)',	'NH3 (ug/m3)',	'SO2 (ug/m3)',	'CO (mg/m3)',	'Ozone (ug/m3)']]
Y= df['AQI']
X.head()

Y.head()

"""Training and Testing Data"""

X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=70)
print(X_train.shape,X_test.shape,Y_train.shape,Y_test.shape)

"""**Prediction Algorithms**

**LINEAR REGRESSION**
"""

model=LinearRegression()
lin_reg = model.fit(X_train,Y_train)
print(lin_reg)

# evaluating its performance on the testing data
train_pred = lin_reg.predict(X_train)
test_pred = lin_reg.predict(X_test)
RMSE_train=(np.sqrt(metrics.mean_squared_error(Y_train,train_pred)))
RMSE_test=(np.sqrt(metrics.mean_squared_error(Y_test,test_pred)))
print("RMSE TrainingData = ",RMSE_train)
print("RMSE TestData = ",RMSE_test)

score = lin_reg.score(X_test, Y_test)
lr_score = np.mean(score)
print('Accuracy : %.3f' % (lr_score))
print('Accuracy percentage : ' + " {:.2f}%".format(np.mean(score) * 100))

"""**Classification Algorithms**"""

import warnings
warnings.filterwarnings("ignore")

from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report

# Splitting the data into independent and dependent columns for classification
X2 = df[['PM2.5 (ug/m3)',	'PM10 (ug/m3)',	'NO (ug/m3)','NO2 (ug/m3)',	'NOx (ppb)',	'NH3 (ug/m3)',	'SO2 (ug/m3)',	'CO (mg/m3)',	'Ozone (ug/m3)']]
Y2 = df['AQI_Range']

# Splitting the data into training and testing data
X_train2, X_test2, Y_train2, Y_test2 = train_test_split(X2, Y2, test_size=0.2, random_state=70)
print(X_train2.shape,X_test2.shape,Y_train2.shape,Y_test2.shape)

"""**Logistic Regression**"""

#fit the model on train data
log_reg = LogisticRegression(C=1, penalty='l2', solver='liblinear',max_iter=200).fit(X_train2, Y_train2)

#predict on train
train_preds2 = log_reg.predict(X_train2)

#accuracy on train
print("Model accuracy on train is: ", accuracy_score(Y_train2, train_preds2))

#predict on test
test_preds2 = log_reg.predict(X_test2)
#accuracy on test
print("Model accuracy on test is: ", accuracy_score(Y_test2, test_preds2))
print('-'*50)

# Kappa Score.
print('KappaScore is: ', metrics.cohen_kappa_score(Y_test2,test_preds2))

print("Accuracy:", accuracy_score(Y_test2, test_preds2))
print("Classification Report:")
print(classification_report(Y_test2, test_preds2))
print("Confusion Matrix:")
print(confusion_matrix(Y_test2, test_preds2))

p = log_reg.predict([[23.00,45.50,2.65,14.65,9.95,6.90,10.50,0.79,51.65]])
q = log_reg.predict([[24.25,145.00,1.02,9.38,5.83,12.55,14.25,0.26,116.22]])
r = log_reg.predict([[127,227.55,62.2,150,12,10,49,10,30]])
print(p)
print(q)
print(r)

"""Decision Tree Classifier"""

dtree = DecisionTreeClassifier()

# Train Decision Tree Classifer
dtree.fit(X_train2,Y_train2)

#predict on train
train_preds7 = dtree.predict(X_train2)

#accuracy on train
print("Model accuracy on train is: ", accuracy_score(Y_train2, train_preds7))

#predict on test
test_preds7 = dtree.predict(X_test2)
#accuracy on test
print("Model accuracy on test is: ", accuracy_score(Y_test2, test_preds7))
print('-'*50)

print("Accuracy:", accuracy_score(Y_test2, test_preds7))
print("Classification Report:")
print(classification_report(Y_test2, test_preds7))
print("Confusion Matrix:")
print(confusion_matrix(Y_test2, test_preds7))

"""**Applying Cross_validation on Decision Tree Classifier**"""

from sklearn.model_selection import cross_val_score
dtclassifier = DecisionTreeClassifier()
print(cross_val_score(dtclassifier, X2, Y2, cv=10, scoring='accuracy').mean())

"""Random Forest Classifier"""

rfc = RandomForestClassifier(n_estimators=100)

# Train Random Forest Classifer
rfc.fit(X_train2, Y_train2)

#predict on train
train_preds6 = rfc.predict(X_train2)

#accuracy on train
print("Model accuracy on train is: ", accuracy_score(Y_train2, train_preds6))

#predict on test
test_preds6 = rfc.predict(X_test2)
#accuracy on test
print("Model accuracy on test is: ", accuracy_score(Y_test2, test_preds6))
print('-'*50)

print("Accuracy:", accuracy_score(Y_test2, test_preds6))
print("Classification Report:")
print(classification_report(Y_test2, test_preds6))
print("Confusion Matrix:")
print(confusion_matrix(Y_test2, test_preds6))

"""**Applying Cross_validation on Random Forest Classifier**"""

from sklearn.model_selection import cross_val_score
rfclassifier = RandomForestClassifier()
print(cross_val_score(rfclassifier, X2, Y2, cv=10, scoring='accuracy').mean())

"""Support Vector Machine"""

s=SVC()

#fit the model on train data
s.fit(X_train2,Y_train2)

#predict on train
train_preds3 = s.predict(X_train2)

#accuracy on train
print("Model accuracy on train is: ", accuracy_score(Y_train2, train_preds3))

#predict on test
test_preds3 = s.predict(X_test2)
#accuracy on test
print("Model accuracy on test is: ", accuracy_score(Y_test2, test_preds3))
print('-'*50)

print("Accuracy:", accuracy_score(Y_test2, test_preds3))
print("Classification Report:")
print(classification_report(Y_test2, test_preds3))
print("Confusion Matrix:")
print(confusion_matrix(Y_test2, test_preds3))

"""K-Nearest Neighbours"""

import warnings
warnings.filterwarnings("ignore")

#fit the model on train data
KNN = KNeighborsClassifier(n_neighbors=50).fit(X_train2,Y_train2)

#predict on train
train_preds5 = KNN.predict(X_train2)
#accuracy on train
print("Model accuracy on train is: ", accuracy_score(Y_train2, train_preds5))

#predict on test
test_preds5 = KNN.predict(X_test2)
#accuracy on test
print("Model accuracy on test is: ", accuracy_score(Y_test2, test_preds5))
print('-'*50)

# Kappa Score
print('KappaScore is: ', metrics.cohen_kappa_score(Y_test2,test_preds5))

print("Accuracy:", accuracy_score(Y_test2, test_preds5))
print("Classification Report:")
print(classification_report(Y_test2, test_preds5))
print("Confusion Matrix:")
print(confusion_matrix(Y_test2, test_preds5))

a=KNN.predict([[24.25,145.00,1.02,9.38,5.83,12.55,14.25,0.26,116.22]])
b=KNN.predict([[23.00,45.50,2.65,14.65,9.95,6.90,10.50,0.79,51.65]])
c=KNN.predict([[127,227.55,62.2,150,12,10,49,10,30]])
print(a)
print(b)
print(c)

"""Accuracy :

*   Linear Regression: 0.9439   
*   Decision Tree Classifier: 0.99988
*   Random Forest Classifier: 0.99978
*   Logistic Regression: 0.77015
*   Support Vector Machine: 0.96621
*   K-Nearest Neighbour: 0.97404

Displaying results on a bar plot
"""

plt.figure(figsize=(12, 6))
plt.bar(["Linear Regression","Decision Tree Classifier","Random Forest Classifier","Logistic Regression","Support Vector Machine","K-Nearest Neighbour"], [0.9439, 0.99988, 0.99978, 0.77015, 0.96621 ,0.97404], color='lightgreen', width = 0.4)
plt.xlabel('Algorithms')
plt.ylabel('Accuracy')
plt.title('Accuracy of Different Machine Learning Algorithms')
plt.xticks(rotation=0)
plt.ylim(0, 1)  # Set y-axis limit from 0 to 1 (since accuracy is between 0 and 1)
plt.tight_layout()
plt.show()

#Create a Pickle file using serialization
import pickle

pickle_out = open("classifier.pkl","wb")
pickle.dump(rfc, pickle_out)
pickle_out.close()